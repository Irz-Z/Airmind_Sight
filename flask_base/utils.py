import requests
import time
import math
import os
import datetime
import json
from collections import defaultdict

# ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á
ALIAS_TO_PROVINCE = {
    "‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä": "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤",
    "‡∏Å‡∏ó‡∏°": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£",
    "‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£",
    "‡∏û‡∏±‡∏ó‡∏¢‡∏≤": "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
    "‡∏≠‡∏∏‡∏ö‡∏•": "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ",
    "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô": "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô",
    "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà": "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà",
    "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
    "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà": "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà",
    "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ": "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ"
}

# AirVisual API Key (Community tier: 10,000 calls/year, expires Jul 8, 2026)
AIRVISUAL_API_KEY = "eeb3ba1c-2778-4b29-a766-30a21e6fa7c8"
API_CALL_COUNT = 0  # ‡∏ï‡∏±‡∏ß‡∏ô‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API
MAX_API_CALLS = 10000  # ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ï‡πà‡∏≠‡∏õ‡∏µ

# Global cache for air quality data
AIR_QUALITY_CACHE = {}

# Directory for daily JSON cache files
CACHE_DIR = "cache"

def normalize_province_name(name):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°"""
    return ALIAS_TO_PROVINCE.get(name.strip().lower(), name.strip())

def normalize_place_name(name):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥"""
    if not name:
        return "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
    # Remove excess spaces, convert to lowercase, and remove unnecessary words
    normalized = name.strip().lower()
    # Remove common or unnecessary words that might cause false duplicates
    words_to_remove = ['the', 'a', 'an', 'hotel', 'resort', 'restaurant', 'temple', 'wat', 'museum', 'zoo', 'viewpoint', 'attraction', 'tourism', 'center', 'shopping']
    words = normalized.split()
    filtered_words = [word for word in words if word not in words_to_remove]
    return ' '.join(filtered_words)

def remove_duplicates(places):
    """‡∏•‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß"""
    if not places:
        return places
    
    seen_names = set()
    unique_places = []
    
    for place in places:
        place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        normalized_name = normalize_place_name(place_name)
        
        if normalized_name and normalized_name not in seen_names and normalized_name != "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏":
            seen_names.add(normalized_name)
            unique_places.append(place)
        elif normalized_name == "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏":  # Keep places with unknown names but don't filter by them
            unique_places.append(place)
    
    return unique_places

def calculate_distance(lat1, lon1, lat2, lon2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î (Haversine formula) ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡πÇ‡∏•‡πÄ‡∏°‡∏ï‡∏£"""
    R = 6371  # Radius of Earth in kilometers
    
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    
    a = (math.sin(dlat/2)**2 + 
         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2)**2)
    
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    distance = R * c
    
    return distance

def get_nearest_air_quality_data():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏û‡∏¥‡∏Å‡∏±‡∏î) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ AirVisual API"""
    global API_CALL_COUNT
    
    if API_CALL_COUNT >= MAX_API_CALLS:
        print(f"‚ö†Ô∏è  ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API ‡πÅ‡∏•‡πâ‡∏ß ({MAX_API_CALLS} calls/year)")
        return None
    
    url = f"http://api.airvisual.com/v2/nearest_city?key={AIRVISUAL_API_KEY}"
    
    try:
        response = requests.get(url, timeout=15)
        API_CALL_COUNT += 1 # Increment API call count
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                city_data = data['data']
                return {
                    'city': city_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'state': city_data.get('state', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'country': city_data.get('country', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'coordinates': city_data.get('location', {}).get('coordinates', [0, 0]),
                    'pollution': city_data.get('current', {}).get('pollution', {}),
                    'weather': city_data.get('current', {}).get('weather', {})
                }
            else:
                print(f"‚ùå AirVisual API Error: {data.get('data', {}).get('message', 'Unknown error')}")
                return None
        elif response.status_code == 429:
            print(f"‚ö†Ô∏è  API Rate limit - ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà (API calls: {API_CALL_COUNT}/{MAX_API_CALLS})")
            time.sleep(2) # Wait a bit if rate limited
            return None
        else:
            print(f"‚ùå HTTP {response.status_code} - AirVisual API calls: {API_CALL_COUNT}/{MAX_API_CALLS}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ (Request Error): {e}")
        return None
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {e}")
        return None

def get_air_quality_stations(province_name):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å AirVisual API (‡πÉ‡∏ä‡πâ nearest city ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)"""
    print(f"\nüå¨Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô {province_name}...")
    print(f"üìä API calls ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ: {API_CALL_COUNT}/{MAX_API_CALLS}")
    
    # Use nearest city API to get air quality data
    air_quality_data = get_nearest_air_quality_data()
    if air_quality_data:
        return [air_quality_data] # Return as a list for consistency
    return []

def get_air_quality_by_coordinates(lat, lon):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ cache ‡πÅ‡∏•‡∏∞ fallback ‡πÑ‡∏õ‡∏¢‡∏±‡∏á nearest city API"""
    global API_CALL_COUNT, AIR_QUALITY_CACHE
    
    # Create cache key (round coordinates to group nearby areas)
    cache_key = (round(lat, 1), round(lon, 1))
    
    # Check cache first
    if cache_key in AIR_QUALITY_CACHE:
        return AIR_QUALITY_CACHE[cache_key]
    
    if API_CALL_COUNT >= MAX_API_CALLS:
        print(f"‚ö†Ô∏è  ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API ‡πÅ‡∏•‡πâ‡∏ß ({MAX_API_CALLS} calls/year). ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        # Use data from the nearest city if API limit is reached
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data # Cache this fallback data
        return nearest_data
    
    url = f"http://api.airvisual.com/v2/nearest_city?lat={lat}&lon={lon}&key={AIRVISUAL_API_KEY}"
    
    try:
        response = requests.get(url, timeout=15)
        API_CALL_COUNT += 1 # Increment API call count
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                city_data = data['data']
                air_quality_data = {
                    'city': city_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'state': city_data.get('state', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'country': city_data.get('country', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'coordinates': city_data.get('location', {}).get('coordinates', [lon, lat]),
                    'pollution': city_data.get('current', {}).get('pollution', {}),
                    'weather': city_data.get('current', {}).get('weather', {})
                }
                AIR_QUALITY_CACHE[cache_key] = air_quality_data # Cache the fetched data
                return air_quality_data
            else:
                print(f"‚ùå AirVisual API Error for coordinates ({lat},{lon}): {data.get('data', {}).get('message', 'Unknown error')}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
                nearest_data = get_nearest_air_quality_data()
                AIR_QUALITY_CACHE[cache_key] = nearest_data
                return nearest_data
        elif response.status_code == 429:
            print(f"‚ö†Ô∏è  API Rate limit - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô")
            nearest_data = get_nearest_air_quality_data()
            AIR_QUALITY_CACHE[cache_key] = nearest_data
            return nearest_data
        else:
            print(f"‚ùå HTTP {response.status_code} - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô")
            nearest_data = get_nearest_air_quality_data()
            AIR_QUALITY_CACHE[cache_key] = nearest_data
            return nearest_data
    except requests.exceptions.RequestException as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ (Request Error) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ({lat},{lon}): {e}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data
        return nearest_data
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ({lat},{lon}): {e}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data
        return nearest_data

def get_aqi_level_description(aqi):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ AQI ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏µ"""
    if aqi <= 50:
        return "‡∏î‡∏µ‡∏°‡∏≤‡∏Å üü¢", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 100:
        return "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á üü°", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏û‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‡∏Ñ‡∏ô‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á"
    elif aqi <= 150:
        return "‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á üü†", "‡∏Ñ‡∏ô‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 200:
        return "‡πÑ‡∏°‡πà‡∏î‡∏µ üî¥", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 300:
        return "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å üü£", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    else:
        return "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‚ö´", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£"

def display_air_quality_info(air_quality_data):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not air_quality_data:
        print("   ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
        return
    
    pollution = air_quality_data.get('pollution', {})
    weather = air_quality_data.get('weather', {})
    
    print(f"   üå¨Ô∏è  ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {air_quality_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
    
    if pollution:
        aqi = pollution.get('aqius', 0)
        main_pollutant = pollution.get('mainus', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        level, description = get_aqi_level_description(aqi)
        
        print(f"   üìä AQI (US): {aqi} - {level}")
        print(f"   üí® ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å: {main_pollutant}")
        print(f"   ‚ÑπÔ∏è  {description}")
    
    if weather:
        temp = weather.get('tp', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        humidity = weather.get('hu', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        pressure = weather.get('pr', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        
        print(f"   üå°Ô∏è  ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: {temp}¬∞C | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: {humidity}% | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏î‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {pressure} hPa")

def get_nominatim_places(province_name, place_type="tourism", limit=5):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Nominatim (OpenStreetMap)"""
    query = f"{place_type} in {province_name}, Thailand"
    params = {
        'q': query,
        'format': 'json',
        'limit': limit * 2,  # Fetch more than target to allow for deduplication
        'addressdetails': 1,
        'extratags': 1
    }
    headers = {
        'User-Agent': 'Thailand Tourism App (educational purpose)' # Important for Nominatim
    }
    try:
        response = requests.get(
            "https://nominatim.openstreetmap.org/search",
            params=params,
            headers=headers,
            timeout=10
        )
        response.raise_for_status() # Raise an exception for HTTP errors
        data = response.json()
        places = []
        for item in data:
            place_info = {
                'name': item.get('display_name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏').split(',')[0] or '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏', # Take first part for name
                'full_address': item.get('display_name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                'lat': float(item.get('lat', 0)),
                'lon': float(item.get('lon', 0)),
                'type': item.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                'importance': item.get('importance', 0)
            }
            places.append(place_info)
        
        # Deduplicate and limit the number of results
        unique_places = remove_duplicates(places)
        return unique_places[:limit]
    except requests.exceptions.RequestException as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Nominatim API: {e}")
        return []
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Nominatim: {e}")
        return []

def enrich_places_with_air_quality(places):
    """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏´‡πà‡∏á"""
    enriched_places = []
    for place in places:
        if place.get('lat') and place.get('lon'):
            air_quality = get_air_quality_by_coordinates(place['lat'], place['lon'])
            if air_quality and air_quality.get('pollution'):
                aqi = air_quality['pollution'].get('aqius', 0)
                pm25 = air_quality['pollution'].get('p2', 0) # PM2.5
                pm10 = air_quality['pollution'].get('p1', 0) # PM10
                level, description = get_aqi_level_description(aqi)
                
                place['air_quality'] = {
                    'aqi': aqi if aqi else 0,
                    'pm25': pm25 if pm25 else 0,
                    'pm10': pm10 if pm10 else 0,
                    'level': level,
                    'description': description,
                    'city': air_quality.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
                }
            else:
                place['air_quality'] = {
                    'aqi': 0,
                    'pm25': 0,
                    'pm10': 0,
                    'level': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                    'description': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                    'city': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                } # Default values when no air quality data is found
        enriched_places.append(place)
    return enriched_places


def group_places_by_air_quality(places):
    """‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AQI"""
    global API_CALL_COUNT
    
    if not places:
        return []
    
    grouped_places = defaultdict(list)
    
    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà... (API calls: {API_CALL_COUNT}/{MAX_API_CALLS})")
    
    for place in places:
        if place.get('lat') and place.get('lon'):
            lat, lon = place['lat'], place['lon']
            
            # Fetch air quality data (with cache and fallback)
            air_quality_data = get_air_quality_by_coordinates(lat, lon)
            place['air_quality'] = air_quality_data
            
            # Group by air quality station's city/state for display purposes
            if air_quality_data:
                station_key = (air_quality_data.get('city', 'Unknown'), 
                              air_quality_data.get('state', 'Unknown'))
                grouped_places[station_key].append(place)
            else:
                grouped_places[('‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö', '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö')].append(place) # Group places without AQI
            
            # Add a small delay to avoid hitting API rate limits too quickly
            time.sleep(0.5)
    
    return grouped_places

def display_places_with_air_quality(places, title):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not places:
        print(f"\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {title}")
        return
    
    print(f"\nüìç {title}")
    print("-" * 50)
    
    # Group places by air quality for better presentation
    grouped_places = group_places_by_air_quality(places)
    
    for station_info, place_list in grouped_places.items():
        station_city, station_state = station_info
        print(f"\nüè¢ ‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î: {station_city}, {station_state}")
        print("-" * 30)
        
        # Display air quality info once per group
        if place_list and place_list[0].get('air_quality'):
            display_air_quality_info(place_list[0]['air_quality'])
            print()
        
        # Display list of places in the group
        for i, place in enumerate(place_list, 1):
            print(f"   {i}. {place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
            if place.get('type'):
                print(f"      üè∑Ô∏è  ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {place.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
            else:
                print(f"      üè∑Ô∏è  ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            if place.get('full_address'):
                print(f"      üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: {place.get('full_address', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')[:100]}...")
            else:
                print(f"      üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            if place.get('lat') and place.get('lon'):
                lat, lon = place['lat'], place['lon']
                print(f"      üó∫Ô∏è  ‡∏û‡∏¥‡∏Å‡∏±‡∏î: {lat:.4f}, {lon:.4f}")
                print(f"      üåê ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà: https://maps.google.com/?q={lat},{lon}")
            else:
                print(f"      üó∫Ô∏è  ‡∏û‡∏¥‡∏Å‡∏±‡∏î: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            print()

def display_places(places, title):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not places:
        print(f"\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {title}")
        return
    
    print(f"\nüìç {title}")
    print("-" * 50)
    
    for i, place in enumerate(places, 1):
        print(f"{i}. {place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
        if place.get('type'):
            print(f"   üè∑Ô∏è  ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {place.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
        else:
            print(f"   üè∑Ô∏è  ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        if place.get('full_address'):
            print(f"   üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: {place.get('full_address', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')[:100]}...")
        else:
            print(f"   üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        if place.get('lat') and place.get('lon'):
            lat, lon = place['lat'], place['lon']
            print(f"   üó∫Ô∏è  ‡∏û‡∏¥‡∏Å‡∏±‡∏î: {lat:.4f}, {lon:.4f}")
            print(f"   üåê ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà: https://maps.google.com/?q={lat},{lon}")
        else:
            print(f"   üó∫Ô∏è  ‡∏û‡∏¥‡∏Å‡∏±‡∏î: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        print()

def show_api_menu():
    """‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏ô‡∏π‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    print("\n" + "="*60)
    print("üèõÔ∏è ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÑ‡∏ó‡∏¢ + ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
    print("="*60)
    print(f"üìä API Usage: {API_CALL_COUNT}/{MAX_API_CALLS} calls used")
    print(f"üóÇÔ∏è  Cache: {len(AIR_QUALITY_CACHE)} ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥")
    print("-"*60)
    print("1. üìç ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("2. üè® ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏° (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("3. üçΩÔ∏è  ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("4. üéØ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("5. üå¨Ô∏è  ‡∏î‡∏π‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
    print("6. üìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏® - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î API)")
    print("7. üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Cache")
    print("0. ‚ùå ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    print("-"*60)

def get_combined_tourism(province_name, limit=5):
    """‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏î/‡∏®‡∏≤‡∏™‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô"""
    tourism_types = [
        ("tourism", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß"),
        ("attraction", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à"),
        ("viewpoint", "‡∏à‡∏∏‡∏î‡∏ä‡∏°‡∏ß‡∏¥‡∏ß"),
        ("museum", "‡∏û‡∏¥‡∏û‡∏¥‡∏ò‡∏†‡∏±‡∏ì‡∏ë‡πå"),
        ("zoo", "‡∏™‡∏ß‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå"),
        ("place of worship", "‡∏ß‡∏±‡∏î/‡∏®‡∏≤‡∏™‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô") # Added this type
    ]
    
    print(f"\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô {province_name}")
    print("=" * 50)
    
    all_results = []
    total_found = 0
    
    for place_type, thai_name in tourism_types:
        places = get_nominatim_places(province_name, place_type, limit=limit) # Use passed limit
        found_count = len(places)
        total_found += found_count
        
        # Display search results for each type
        if found_count > 0:
            print(f"‚úÖ {thai_name}: ‡∏û‡∏ö {found_count} ‡πÅ‡∏´‡πà‡∏á")
        else:
            print(f"‚ùå {thai_name}: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            
        all_results.extend(places)
        
        # Stop once enough places are found (if limit is effective)
        if len(all_results) >= limit:
            break
    
    # Deduplicate and limit the final results
    unique_results = remove_duplicates(all_results)
    final_results = unique_results[:limit]
    
    print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:")
    print(f"   üî¢ ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö‡∏ã‡πâ‡∏≥): {total_found} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print(f"   üîÑ ‡∏´‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏ã‡πâ‡∏≥: {len(unique_results)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print(f"   üìç ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•: {len(final_results)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print("-" * 50)
    
    return final_results

# --- Cache Management Functions ---
def get_cache_file_path(province_name):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
    today = datetime.date.today().strftime("%Y-%m-%d")
    # Sanitize province_name for filename
    safe_province_name = "".join(c for c in province_name if c.isalnum() or c in (' ', '_')).replace(' ', '_')
    filename = f"{safe_province_name}_{today}.json"
    return os.path.join(CACHE_DIR, filename)

def load_from_cache(province_name):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô)"""
    file_path = get_cache_file_path(province_name)
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache: {file_path}")
                return data
        except json.JSONDecodeError as e:
            print(f"‚ùå Cache file ‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ {file_path}: {e}")
            os.remove(file_path) # Remove corrupted file
            return None
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î cache ‡∏à‡∏≤‡∏Å {file_path}: {e}")
            return None
    return None

def save_to_cache(province_name, data):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô cache file"""
    os.makedirs(CACHE_DIR, exist_ok=True) # Ensure cache directory exists
    file_path = get_cache_file_path(province_name)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4) # Use indent for readability
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á cache: {file_path}")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å cache ‡∏•‡∏á {file_path}: {e}")

def rank_places_by_dust(places, dust_type='aqius'):
    """
    ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® (‡∏ù‡∏∏‡πà‡∏ô) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å)
    Parameters:
    - places: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'air_quality' dict
    - dust_type: ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ù‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö ('aqius', 'pm25', 'pm10')
    """
    if not places:
        return []

    # Map user-friendly dust_type to actual keys in air_quality dict
    if dust_type == 'pm25':
        actual_dust_key = 'pm25'
    elif dust_type == 'pm10':
        actual_dust_key = 'pm10'
    else:  # Default to AQI US
        actual_dust_key = 'aqi'

    places_with_dust_data = []
    places_without_dust_data = []

    for place in places:
        air_quality = place.get('air_quality')
        if air_quality and air_quality.get(actual_dust_key) is not None:
            places_with_dust_data.append(place)
        else:
            places_without_dust_data.append(place)

    # Sort places with dust data by the specified dust_type in ascending order (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å)
    places_with_dust_data.sort(key=lambda x: x['air_quality'][actual_dust_key])

    # Combine sorted places with those without dust data (these will appear at the end)
    return places_with_dust_data + places_without_dust_data


# === Time Series Functions ===
def get_time_series_data(province_name, start_date, end_date, interval='daily'):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ cache ‡πÅ‡∏•‡∏∞ API
    """
    import datetime
    from datetime import timedelta
    import json
    import os
    
    try:
        start = datetime.datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.datetime.strptime(end_date, '%Y-%m-%d')
    except ValueError:
        print("‚ùå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö YYYY-MM-DD")
        return []
    
    if start > end:
        print("‚ùå ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
        return []
    
    print(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    places = get_combined_tourism(province_name, limit=3)
    
    if not places:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î {province_name}")
        return []
    
    time_series_data = []
    current_date = start.date()
    end_date_obj = end.date()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå cache ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    cache_dir = os.path.join(os.path.dirname(__file__), 'cache')
    os.makedirs(cache_dir, exist_ok=True)
    
    print(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {len(places)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    
    while current_date <= end_date_obj:
        date_str = current_date.strftime('%Y-%m-%d')
        
        for place in places:
            if not place.get('lat') or not place.get('lon'):
                continue
                
            place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
            
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô cache ‡∏Å‡πà‡∏≠‡∏ô
            cached_data = get_cached_historical_data(place_name, date_str, cache_dir)
            
            if cached_data:
                # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache
                time_series_data.append({
                    'date': date_str,
                    'place_name': place_name,
                    'lat': place['lat'],
                    'lon': place['lon'],
                    'aqi': cached_data.get('aqi', 0),
                    'pm25': cached_data.get('pm25', 0),
                    'pm10': cached_data.get('pm10', 0),
                    'city': cached_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'is_historical': True,
                    'source': 'cache'
                })
                print(f"  üìÅ {date_str}: {place_name} - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache")
            else:
                # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô cache ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á
                if current_date < datetime.date.today():
                    simulated_data = create_realistic_historical_data(
                        place, current_date, province_name
                    )
                    
                    time_series_data.append(simulated_data)
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á cache
                    save_to_time_series_cache(place_name, date_str, simulated_data, cache_dir)
                    print(f"  üîÑ {date_str}: {place_name} - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                elif current_date == datetime.date.today():
                    # ‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å API
                    try:
                        current_air = get_air_quality_by_coordinates(place['lat'], place['lon'])
                        if current_air and current_air.get('pollution'):
                            real_data = {
                                'date': date_str,
                                'place_name': place_name,
                                'lat': place['lat'],
                                'lon': place['lon'],
                                'aqi': current_air['pollution'].get('aqius', 0),
                                'pm25': current_air['pollution'].get('p2', 0),
                                'pm10': current_air['pollution'].get('p1', 0),
                                'city': current_air.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                                'is_historical': False,
                                'source': 'api_realtime'
                            }
                            time_series_data.append(real_data)
                            print(f"  üåê {date_str}: {place_name} - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å API")
                    except Exception as e:
                        print(f"  ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {place_name}: {e}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≤‡∏° interval
        if interval == 'daily':
            current_date += timedelta(days=1)
        elif interval == 'weekly':
            current_date += timedelta(weeks=1)
        elif interval == 'monthly':
            # ‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            if current_date.month == 12:
                current_date = current_date.replace(year=current_date.year + 1, month=1)
            else:
                current_date = current_date.replace(month=current_date.month + 1)
    
    print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(time_series_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return time_series_data

def get_cached_historical_data(place_name, date_str, cache_dir):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    """
    try:
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        safe_place_name = "".join(c for c in place_name if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        cache_file = os.path.join(cache_dir, f"{safe_place_name}_{date_str}.json")
        
        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô cache: {e}")
    return None

def save_to_time_series_cache(place_name, date_str, data, cache_dir):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á time series cache
    """
    try:
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        safe_place_name = "".join(c for c in place_name if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        cache_file = os.path.join(cache_dir, f"{safe_place_name}_{date_str}.json")
        
        cache_data = {
            'aqi': data.get('aqi', 0),
            'pm25': data.get('pm25', 0),
            'pm10': data.get('pm10', 0),
            'city': data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            'cached_at': datetime.datetime.now().isoformat()
        }
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å cache: {e}")

def create_realistic_historical_data(place, date, province_name):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pattern ‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•‡πÅ‡∏•‡∏∞‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    """
    import random
    import math
    
    place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    base_aqi = 45
    base_pm25 = 22
    base_pm10 = 35
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    area_type = classify_area_type(place_name, province_name)
    
    if area_type == 'urban':  # ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏´‡∏ç‡πà
        base_aqi += 20
        base_pm25 += 12
        base_pm10 += 15
    elif area_type == 'industrial':  # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
        base_aqi += 35
        base_pm25 += 18
        base_pm10 += 25
    elif area_type == 'rural':  # ‡∏ä‡∏ô‡∏ö‡∏ó
        base_aqi -= 10
        base_pm25 -= 8
        base_pm10 -= 10
    elif area_type == 'coastal':  # ‡∏ä‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏•
        base_aqi -= 5
        base_pm25 -= 5
        base_pm10 -= 8
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•
    month = date.month
    seasonal_multiplier = 1.0
    
    if month in [12, 1, 2]:  # ‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß
        seasonal_multiplier = 1.15
    elif month in [3, 4]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏ï‡πâ‡∏ô - ‡∏´‡∏°‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏±‡∏ô
        seasonal_multiplier = 1.45
    elif month in [5]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏õ‡∏•‡∏≤‡∏¢
        seasonal_multiplier = 1.25
    elif month in [6, 7, 8, 9, 10]:  # ‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_multiplier = 0.65
    elif month in [11]:  # ‡∏´‡∏•‡∏±‡∏á‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_multiplier = 0.8
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå
    weekday_factor = 1.1 if date.weekday() < 5 else 0.9  # ‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ vs ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
    
    # ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏ö‡∏ö sine wave ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
    day_of_year = date.timetuple().tm_yday
    natural_variation = 1.0 + (0.1 * math.sin(2 * math.pi * day_of_year / 365))
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏∏‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô
    daily_random = random.uniform(0.8, 1.2)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    total_factor = seasonal_multiplier * weekday_factor * natural_variation * daily_random
    
    final_aqi = int(base_aqi * total_factor)
    final_pm25 = int(base_pm25 * total_factor)
    final_pm10 = int(base_pm10 * total_factor)
    
    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
    final_aqi = max(15, min(200, final_aqi))
    final_pm25 = max(8, min(120, final_pm25))
    final_pm10 = max(15, min(150, final_pm10))
    
    return {
        'date': date.strftime('%Y-%m-%d'),
        'place_name': place_name,
        'lat': place['lat'],
        'lon': place['lon'],
        'aqi': final_aqi,
        'pm25': final_pm25,
        'pm10': final_pm10,
        'city': place.get('province', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
        'is_historical': True,
        'source': 'generated_realistic'
    }

def classify_area_type(place_name, province_name):
    """
    ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏°‡∏•‡∏û‡∏¥‡∏©
    """
    urban_keywords = ['‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', '‡∏´‡πâ‡∏≤‡∏á', '‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ', '‡∏ï‡∏•‡∏≤‡∏î', '‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•', '‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢']
    industrial_keywords = ['‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô', '‡∏ô‡∏¥‡∏Ñ‡∏°', '‡∏ó‡πà‡∏≤‡πÄ‡∏£‡∏∑‡∏≠', '‡∏™‡∏ô‡∏≤‡∏°‡∏ö‡∏¥‡∏ô']
    coastal_keywords = ['‡∏´‡∏≤‡∏î', '‡∏ó‡∏∞‡πÄ‡∏•', '‡πÄ‡∏Å‡∏≤‡∏∞', '‡∏≠‡πà‡∏≤‡∏ß']
    rural_keywords = ['‡∏ß‡∏±‡∏î', '‡∏õ‡πà‡∏≤', '‡∏†‡∏π‡πÄ‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏ï‡∏Å', '‡∏≠‡∏∏‡∏ó‡∏¢‡∏≤‡∏ô']
    
    place_lower = place_name.lower()
    
    if any(keyword in place_lower for keyword in industrial_keywords):
        return 'industrial'
    elif any(keyword in place_lower for keyword in urban_keywords):
        return 'urban'
    elif any(keyword in place_lower for keyword in coastal_keywords):
        return 'coastal'
    elif any(keyword in place_lower for keyword in rural_keywords):
        return 'rural'
    
    # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    if province_name.lower() in ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ']:
        return 'urban'
    elif province_name.lower() in ['‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ']:
        return 'industrial'
    elif province_name.lower() in ['‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤']:
        return 'coastal'
    else:
        return 'rural'

def analyze_time_series_ranking(time_series_data, sort_by='aqi'):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series
    """
    if not time_series_data:
        return {}
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
    place_stats = {}
    
    for data in time_series_data:
        place_name = data['place_name']
        if place_name not in place_stats:
            place_stats[place_name] = {
                'name': place_name,
                'values': [],
                'dates': [],
                'lat': data['lat'],
                'lon': data['lon'],
                'city': data['city']
            }
        
        place_stats[place_name]['values'].append(data[sort_by])
        place_stats[place_name]['dates'].append(data['date'])
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
    ranking_data = []
    for place_name, stats in place_stats.items():
        values = stats['values']
        
        if values:
            avg_value = sum(values) / len(values)
            min_value = min(values)
            max_value = max(values)
            
            ranking_data.append({
                'name': place_name,
                'lat': stats['lat'],
                'lon': stats['lon'],
                'city': stats['city'],
                'average': round(avg_value, 2),
                'minimum': min_value,
                'maximum': max_value,
                'data_points': len(values),
                'values': values,
                'dates': stats['dates']
            })
    
    # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å = ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
    ranking_data.sort(key=lambda x: x['average'])
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
    for i, place in enumerate(ranking_data, 1):
        place['rank'] = i
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•
        if i == 1:
            place['medal'] = 'ü•á'
        elif i == 2:
            place['medal'] = 'ü•à'
        elif i == 3:
            place['medal'] = 'ü•â'
        else:
            place['medal'] = ''
    
    return {
        'rankings': ranking_data,
        'total_places': len(ranking_data),
        'sort_by': sort_by,
        'best_place': ranking_data[0] if ranking_data else None,
        'worst_place': ranking_data[-1] if ranking_data else None
    }

def display_time_series_ranking(analysis_result):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö time series
    """
    if not analysis_result or not analysis_result.get('rankings'):
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö")
        return
    
    rankings = analysis_result['rankings']
    sort_by = analysis_result['sort_by'].upper()
    
    print(f"\nüèÜ ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® (‡∏ï‡∏≤‡∏° {sort_by})")
    print("=" * 60)
    
    for place in rankings:
        print(f"{place['medal']} {place['rank']}. {place['name']}")
        print(f"   üìä ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {place['average']}")
        print(f"   üìà ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤: {place['minimum']} - {place['maximum']}")
        print(f"   üìÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {place['data_points']} ‡∏à‡∏∏‡∏î")
        print(f"   üìç ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {place['city']}")
        print()
    
    if analysis_result.get('best_place'):
        best = analysis_result['best_place']
        print(f"üåü ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best['name']} (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {best['average']})")
    
    if analysis_result.get('worst_place'):
        worst = analysis_result['worst_place']
        print(f"‚ö†Ô∏è  ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏¢‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {worst['name']} (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {worst['average']})")

def get_forecast_data(province_name, forecast_days=5, interval='daily'):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    ‡πÉ‡∏ä‡πâ OpenWeatherMap API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏®
    """
    import datetime
    from datetime import timedelta
    import random
    
    print(f"üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {forecast_days} ‡∏ß‡∏±‡∏ô")
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    places = get_combined_tourism(province_name, limit=3)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏Ñ‡πà 3 ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î API calls
    
    if not places:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î {province_name}")
        return []
    
    forecast_data = []
    current_date = datetime.date.today()
    
    # OpenWeatherMap API key (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo - ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ key ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á)
    OPENWEATHER_API_KEY = "demo_key"  # Replace with actual API key
    
    print(f"üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≤‡∏Å {len(places)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    
    for place in places:
        if not place.get('lat') or not place.get('lon'):
            continue
            
        lat, lon = place['lat'], place['lon']
        place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        
        try:
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á
            current_air_quality = get_air_quality_by_coordinates(lat, lon)
            
            if current_air_quality and current_air_quality.get('pollution'):
                base_aqi = current_air_quality['pollution'].get('aqius', 50)
                base_pm25 = current_air_quality['pollution'].get('p2', 25)
                base_pm10 = current_air_quality['pollution'].get('p1', 40)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                for day in range(forecast_days):
                    future_date = current_date + timedelta(days=day)
                    date_str = future_date.strftime('%Y-%m-%d')
                    
                    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                    forecast_aqi, forecast_pm25, forecast_pm10 = calculate_realistic_forecast(
                        base_aqi, base_pm25, base_pm10, day, future_date, lat, lon
                    )
                    
                    forecast_data.append({
                        'date': date_str,
                        'place_name': place_name,
                        'lat': lat,
                        'lon': lon,
                        'aqi': forecast_aqi,
                        'pm25': forecast_pm25,
                        'pm10': forecast_pm10,
                        'city': current_air_quality.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                        'is_forecast': True,
                        'confidence': calculate_forecast_confidence(day),
                        'weather_impact': get_weather_impact_factor(future_date),
                        'source': 'calculated_forecast'
                    })
                    
                    print(f"  üìÖ {date_str}: {place_name} - AQI: {forecast_aqi}")
                    
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {place_name}: {e}")
            continue
    
    print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(forecast_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return forecast_data

def calculate_realistic_forecast(base_aqi, base_pm25, base_pm10, day_offset, date, lat, lon):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡πà‡∏≤‡∏á‡πÜ
    """
    import random
    import math
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•
    month = date.month
    seasonal_factor = 1.0
    
    if month in [12, 1, 2]:  # ‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß
        seasonal_factor = 1.15  # ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏´‡πâ‡∏á ‡∏°‡∏µ‡∏ù‡∏∏‡πà‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
    elif month in [3, 4]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏ï‡πâ‡∏ô - ‡∏ä‡πà‡∏ß‡∏á‡∏´‡∏°‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏±‡∏ô
        seasonal_factor = 1.4   # ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ù‡∏∏‡πà‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    elif month in [5]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏õ‡∏•‡∏≤‡∏¢
        seasonal_factor = 1.2   
    elif month in [6, 7, 8, 9, 10]:  # ‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_factor = 0.6   # ‡∏ù‡∏ô‡∏•‡πâ‡∏≤‡∏á‡∏ù‡∏∏‡πà‡∏ô
    elif month in [11]:  # ‡∏´‡∏•‡∏±‡∏á‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_factor = 0.8
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏°‡∏µ‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î)
    weekday_factor = 1.0
    if date.weekday() < 5:  # ‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå
        weekday_factor = 1.1
    else:  # ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
        weekday_factor = 0.9
    
    # ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ö‡∏ö pattern ‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏£‡∏¥‡∏á)
    time_trend = 1.0 + (0.02 * day_offset * random.uniform(-1, 1))
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏∏‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥)
    daily_variation = random.uniform(0.85, 1.15)
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏© (‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÑ‡∏°‡πà‡∏õ‡∏Å‡∏ï‡∏¥)
    special_event_factor = 1.0
    if random.random() < 0.1:  # 10% ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©
        special_event_factor = random.uniform(0.7, 1.3)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    total_factor = seasonal_factor * weekday_factor * time_trend * daily_variation * special_event_factor
    
    forecast_aqi = int(base_aqi * total_factor)
    forecast_pm25 = int(base_pm25 * total_factor)
    forecast_pm10 = int(base_pm10 * total_factor)
    
    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
    forecast_aqi = max(15, min(300, forecast_aqi))
    forecast_pm25 = max(8, min(150, forecast_pm25))
    forecast_pm10 = max(15, min(200, forecast_pm10))
    
    return forecast_aqi, forecast_pm25, forecast_pm10

def calculate_forecast_confidence(day_offset):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (‡∏¢‡∏¥‡πà‡∏á‡πÑ‡∏Å‡∏•‡∏¢‡∏¥‡πà‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô)
    """
    base_confidence = 0.95
    decline_rate = 0.05
    confidence = base_confidence - (day_offset * decline_rate)
    return max(0.6, confidence)  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 60%

def get_weather_impact_factor(date):
    """
    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®
    """
    import random
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®
    factors = {
        'wind': random.uniform(0.8, 1.2),      # ‡∏•‡∏°
        'humidity': random.uniform(0.9, 1.1),  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô
        'pressure': random.uniform(0.95, 1.05), # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏î‡∏≠‡∏≤‡∏Å‡∏≤‡∏®
        'rain_chance': random.uniform(0.0, 1.0)  # ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ù‡∏ô‡∏ï‡∏Å
    }
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ù‡∏ô‡∏ï‡∏Å‡∏™‡∏π‡∏á ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏•‡πâ‡∏≤‡∏á‡∏ù‡∏∏‡πà‡∏ô
    if factors['rain_chance'] > 0.6:
        factors['rain_impact'] = 0.7
    else:
        factors['rain_impact'] = 1.0
    
    return factors

if __name__ == "__main__":
    print("This module is designed to be imported by Flask app, not run directly.")
