import requests
import time
import math
import os
import datetime
import json
from collections import defaultdict

# ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô ‚Üí ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á
ALIAS_TO_PROVINCE = {
    "‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä": "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤",
    "‡∏Å‡∏ó‡∏°": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£",
    "‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å": "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£",
    "‡∏û‡∏±‡∏ó‡∏¢‡∏≤": "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
    "‡∏≠‡∏∏‡∏ö‡∏•": "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ",
    "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô": "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô",
    "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà": "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà",
    "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï": "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
    "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà": "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà",
    "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ": "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ"
}

# ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö forecast data)
DISTRICT_TO_PROVINCE = {
    "‡∏û‡∏¥‡∏°‡∏≤‡∏¢": "Nakhon Ratchasima",
    "‡∏õ‡∏≤‡∏Å‡∏ä‡πà‡∏≠‡∏á": "Nakhon Ratchasima", 
    "‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä": "Nakhon Ratchasima",
    "‡∏û‡∏±‡∏ó‡∏¢‡∏≤": "Chonburi",
    "‡πÄ‡∏Å‡∏≤‡∏∞‡∏ä‡πâ‡∏≤‡∏á": "Trat",
    "‡πÄ‡∏Å‡∏≤‡∏∞‡∏™‡∏°‡∏∏‡∏¢": "Surat Thani",
    "‡∏´‡∏±‡∏ß‡∏´‡∏¥‡∏ô": "Prachuap Khiri Khan",
    "‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤": "Phra Nakhon Si Ayutthaya"
}

# ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏ó‡∏¢ ‚Üí ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö forecast data)
THAI_TO_ENGLISH_PROVINCE = {
    "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£": "Bangkok",
    "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤": "Nakhon Ratchasima",
    "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ": "Chonburi",
    "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà": "Chiang Mai",
    "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï": "Phuket",
    "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà": "Krabi",
    "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ": "Surat Thani",
    "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ": "Ubon Ratchathani",
    "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô": "Khon Kaen",
    "‡∏ï‡∏£‡∏≤‡∏î": "Trat",
    "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå": "Prachuap Khiri Khan",
    "‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤": "Phra Nakhon Si Ayutthaya"
}

# AirVisual API Key (Community tier: 10,000 calls/year, expires Jul 8, 2026)
AIRVISUAL_API_KEY = "eeb3ba1c-2778-4b29-a766-30a21e6fa7c8"
API_CALL_COUNT = 0  # ‡∏ï‡∏±‡∏ß‡∏ô‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API
MAX_API_CALLS = 10000  # ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ï‡πà‡∏≠‡∏õ‡∏µ

# Global cache for air quality data
AIR_QUALITY_CACHE = {}

# Directory for daily JSON cache files
CACHE_DIR = "cache"

def normalize_province_name(name):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°"""
    return ALIAS_TO_PROVINCE.get(name.strip().lower(), name.strip())

def normalize_place_name(name):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥"""
    if not name:
        return "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô
    normalized = name.strip().lower()
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    prefixes_to_remove = ['‡∏ß‡∏±‡∏î', 'wat ', 'temple ', 'the ']
    suffixes_to_remove = [' temple', ' center', ' shopping center']
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤
    for prefix in prefixes_to_remove:
        if normalized.startswith(prefix):
            normalized = normalized[len(prefix):].strip()
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢
    for suffix in suffixes_to_remove:
        if normalized.endswith(suffix):
            normalized = normalized[:-len(suffix)].strip()
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πà
    name_mappings = {
        'grand palace': '‡∏û‡∏£‡∏∞‡∏ö‡∏£‡∏°‡∏°‡∏´‡∏≤‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á',
        'phra si rattana satsadaram': '‡∏û‡∏£‡∏∞‡∏®‡∏£‡∏µ‡∏£‡∏±‡∏ï‡∏ô‡∏®‡∏≤‡∏™‡∏î‡∏≤‡∏£‡∏≤‡∏°',
        'wat phra si rattana satsadaram': '‡∏û‡∏£‡∏∞‡∏®‡∏£‡∏µ‡∏£‡∏±‡∏ï‡∏ô‡∏®‡∏≤‡∏™‡∏î‡∏≤‡∏£‡∏≤‡∏°',
        'emerald buddha temple': '‡∏û‡∏£‡∏∞‡∏®‡∏£‡∏µ‡∏£‡∏±‡∏ï‡∏ô‡∏®‡∏≤‡∏™‡∏î‡∏≤‡∏£‡∏≤‡∏°',
    }
    
    # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if normalized in name_mappings:
        normalized = name_mappings[normalized]
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£
    if '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û' in normalized:
        normalized = normalized.replace(' ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '').replace(' ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û', '')
    
    return normalized

def remove_duplicates(places):
    """‡∏•‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß"""
    if not places:
        return places
    
    seen_names = set()
    unique_places = []
    
    for place in places:
        place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        normalized_name = normalize_place_name(place_name)
        
        if normalized_name and normalized_name not in seen_names and normalized_name != "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏":
            seen_names.add(normalized_name)
            unique_places.append(place)
        elif normalized_name == "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏":  # Keep places with unknown names but don't filter by them
            unique_places.append(place)
    
    return unique_places

def calculate_distance(lat1, lon1, lat2, lon2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î (Haversine formula) ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡πÇ‡∏•‡πÄ‡∏°‡∏ï‡∏£"""
    R = 6371  # Radius of Earth in kilometers
    
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    
    a = (math.sin(dlat/2)**2 + 
         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2)**2)
    
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    distance = R * c
    
    return distance

def get_nearest_air_quality_data():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏û‡∏¥‡∏Å‡∏±‡∏î) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ AirVisual API"""
    global API_CALL_COUNT
    
    if API_CALL_COUNT >= MAX_API_CALLS:
        print(f"  ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API ‡πÅ‡∏•‡πâ‡∏ß ({MAX_API_CALLS} calls/year)")
        return None
    
    url = f"http://api.airvisual.com/v2/nearest_city?key={AIRVISUAL_API_KEY}"
    
    try:
        response = requests.get(url, timeout=15)
        API_CALL_COUNT += 1 # Increment API call count
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                city_data = data['data']
                return {
                    'city': city_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'state': city_data.get('state', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'country': city_data.get('country', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'coordinates': city_data.get('location', {}).get('coordinates', [0, 0]),
                    'pollution': city_data.get('current', {}).get('pollution', {}),
                    'weather': city_data.get('current', {}).get('weather', {})
                }
            else:
                print(f" AirVisual API Error: {data.get('data', {}).get('message', 'Unknown error')}")
                return None
        elif response.status_code == 429:
            print(f"  API Rate limit - ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà (API calls: {API_CALL_COUNT}/{MAX_API_CALLS})")
            time.sleep(2) # Wait a bit if rate limited
            return None
        else:
            print(f" HTTP {response.status_code} - AirVisual API calls: {API_CALL_COUNT}/{MAX_API_CALLS}")
            return None
    except requests.exceptions.RequestException as e:
        print(f" ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ (Request Error): {e}")
        return None
    except Exception as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {e}")
        return None

def get_air_quality_stations(province_name):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å AirVisual API (‡πÉ‡∏ä‡πâ nearest city ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)"""
    print(f"\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô {province_name}...")
    print(f" API calls used: {API_CALL_COUNT}/{MAX_API_CALLS}")
    
    # Use nearest city API to get air quality data
    air_quality_data = get_nearest_air_quality_data()
    if air_quality_data:
        return [air_quality_data] # Return as a list for consistency
    return []

def get_air_quality_by_coordinates(lat, lon):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ cache ‡πÅ‡∏•‡∏∞ fallback ‡πÑ‡∏õ‡∏¢‡∏±‡∏á nearest city API"""
    global API_CALL_COUNT, AIR_QUALITY_CACHE
    
    # Create cache key (round coordinates to group nearby areas)
    cache_key = (round(lat, 1), round(lon, 1))
    
    # Check cache first
    if cache_key in AIR_QUALITY_CACHE:
        return AIR_QUALITY_CACHE[cache_key]
    
    if API_CALL_COUNT >= MAX_API_CALLS:
        print(f"  ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ API ‡πÅ‡∏•‡πâ‡∏ß ({MAX_API_CALLS} calls/year). ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        # Use data from the nearest city if API limit is reached
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data # Cache this fallback data
        return nearest_data
    
    url = f"http://api.airvisual.com/v2/nearest_city?lat={lat}&lon={lon}&key={AIRVISUAL_API_KEY}"
    
    try:
        response = requests.get(url, timeout=15)
        API_CALL_COUNT += 1 # Increment API call count
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                city_data = data['data']
                air_quality_data = {
                    'city': city_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'state': city_data.get('state', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'country': city_data.get('country', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'coordinates': city_data.get('location', {}).get('coordinates', [lon, lat]),
                    'pollution': city_data.get('current', {}).get('pollution', {}),
                    'weather': city_data.get('current', {}).get('weather', {})
                }
                AIR_QUALITY_CACHE[cache_key] = air_quality_data # Cache the fetched data
                return air_quality_data
            else:
                print(f" AirVisual API Error for coordinates ({lat},{lon}): {data.get('data', {}).get('message', 'Unknown error')}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
                nearest_data = get_nearest_air_quality_data()
                AIR_QUALITY_CACHE[cache_key] = nearest_data
                return nearest_data
        elif response.status_code == 429:
            print(f"  API Rate limit - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô")
            nearest_data = get_nearest_air_quality_data()
            AIR_QUALITY_CACHE[cache_key] = nearest_data
            return nearest_data
        else:
            print(f" HTTP {response.status_code} - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô")
            nearest_data = get_nearest_air_quality_data()
            AIR_QUALITY_CACHE[cache_key] = nearest_data
            return nearest_data
    except requests.exceptions.RequestException as e:
        print(f" ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏î‡πâ (Request Error) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ({lat},{lon}): {e}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data
        return nearest_data
    except Exception as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ({lat},{lon}): {e}. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô.")
        nearest_data = get_nearest_air_quality_data()
        AIR_QUALITY_CACHE[cache_key] = nearest_data
        return nearest_data

def get_aqi_level_description(aqi):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ AQI ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏µ"""
    if aqi <= 50:
        return "‡∏î‡∏µ‡∏°‡∏≤‡∏Å GREEN", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 100:
        return "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á YELLOW", "‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏û‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‡∏Ñ‡∏ô‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á"
    elif aqi <= 150:
        return "‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ORANGE", "‡∏Ñ‡∏ô‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 200:
        return "‡πÑ‡∏°‡πà‡∏î‡∏µ RED", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    elif aqi <= 300:
        return "‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å üü£", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏à‡πâ‡∏á"
    else:
        return "‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ BLACK", "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£"

def display_air_quality_info(air_quality_data):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not air_quality_data:
        print("    ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
        return
    
    pollution = air_quality_data.get('pollution', {})
    weather = air_quality_data.get('weather', {})
    
    print(f"     ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {air_quality_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
    
    if pollution:
        aqi = pollution.get('aqius', 0)
        main_pollutant = pollution.get('mainus', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        level, description = get_aqi_level_description(aqi)
        
        print(f"    AQI (US): {aqi} - {level}")
        print(f"   üí® ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å: {main_pollutant}")
        print(f"   ‚ÑπÔ∏è  {description}")
    
    if weather:
        temp = weather.get('tp', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        humidity = weather.get('hu', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        pressure = weather.get('pr', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        
        print(f"   üå°Ô∏è  ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥: {temp}¬∞C | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô: {humidity}% | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏î‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {pressure} hPa")

def get_nominatim_places(province_name, place_type="tourism", limit=5):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Nominatim (OpenStreetMap)"""
    query = f"{place_type} in {province_name}, Thailand"
    params = {
        'q': query,
        'format': 'json',
        'limit': limit * 2,  # Fetch more than target to allow for deduplication
        'addressdetails': 1,
        'extratags': 1
    }
    headers = {
        'User-Agent': 'Thailand Tourism App (educational purpose)' # Important for Nominatim
    }
    try:
        response = requests.get(
            "https://nominatim.openstreetmap.org/search",
            params=params,
            headers=headers,
            timeout=10
        )
        response.raise_for_status() # Raise an exception for HTTP errors
        data = response.json()
        places = []
        for item in data:
            place_info = {
                'name': item.get('display_name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏').split(',')[0] or '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏', # Take first part for name
                'full_address': item.get('display_name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                'lat': float(item.get('lat', 0)),
                'lon': float(item.get('lon', 0)),
                'type': item.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                'importance': item.get('importance', 0)
            }
            places.append(place_info)
        
        # Deduplicate and limit the number of results
        unique_places = remove_duplicates(places)
        return unique_places[:limit]
    except requests.exceptions.RequestException as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Nominatim API: {e}")
        return []
    except Exception as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Nominatim: {e}")
        return []

def enrich_places_with_air_quality(places):
    """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏´‡πà‡∏á"""
    enriched_places = []
    for place in places:
        if place.get('lat') and place.get('lon'):
            air_quality = get_air_quality_by_coordinates(place['lat'], place['lon'])
            if air_quality and air_quality.get('pollution'):
                pollution_data = air_quality['pollution']
                aqi = pollution_data.get('aqius', 0)
                pm25 = pollution_data.get('p2', None) # PM2.5
                pm10 = pollution_data.get('p1', None) # PM10
                
                # If PM2.5 and PM10 are not available, estimate from AQI
                if pm25 is None or pm25 == 0:
                    pm25 = estimate_pm25_from_aqi(aqi)
                if pm10 is None or pm10 == 0:
                    pm10 = estimate_pm10_from_aqi(aqi)
                
                # Debug print to check what we're getting
                print(f"Air quality data for {place.get('name', 'Unknown')}: AQI={aqi}, PM2.5={pm25}, PM10={pm10}")
                
                level, description = get_aqi_level_description(aqi)
                
                # Ensure PM values are properly extracted and handled - convert to int if valid
                place['air_quality'] = {
                    'aqi': int(aqi) if aqi is not None and aqi >= 0 else None,
                    'pm25': int(pm25) if pm25 is not None and pm25 >= 0 else None,
                    'pm10': int(pm10) if pm10 is not None and pm10 >= 0 else None,
                    'level': level,
                    'description': description,
                    'city': air_quality.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
                }
            else:
                print(f"No air quality data available for {place.get('name', 'Unknown')}")
                place['air_quality'] = {
                    'aqi': None,
                    'pm25': None,
                    'pm10': None,
                    'level': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                    'description': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                    'city': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                } # Default values when no air quality data is found
        else:
            print(f"No coordinates available for {place.get('name', 'Unknown')}")
            place['air_quality'] = {
                'aqi': None,
                'pm25': None,
                'pm10': None,
                'level': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                'description': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏',
                'city': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
            }
        enriched_places.append(place)
    return enriched_places


def group_places_by_air_quality(places):
    """‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AQI"""
    global API_CALL_COUNT
    
    if not places:
        return []
    
    grouped_places = defaultdict(list)
    
    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà... (API calls: {API_CALL_COUNT}/{MAX_API_CALLS})")
    
    for place in places:
        if place.get('lat') and place.get('lon'):
            lat, lon = place['lat'], place['lon']
            
            # Fetch air quality data (with cache and fallback)
            air_quality_data = get_air_quality_by_coordinates(lat, lon)
            place['air_quality'] = air_quality_data
            
            # Group by air quality station's city/state for display purposes
            if air_quality_data:
                station_key = (air_quality_data.get('city', 'Unknown'), 
                              air_quality_data.get('state', 'Unknown'))
                grouped_places[station_key].append(place)
            else:
                grouped_places[('‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö', '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö')].append(place) # Group places without AQI
            
            # Add a small delay to avoid hitting API rate limits too quickly
            time.sleep(0.5)
    
    return grouped_places

def display_places_with_air_quality(places, title):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not places:
        print(f"\n ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {title}")
        return
    
    print(f"\n {title}")
    print("-" * 50)
    
    # Group places by air quality for better presentation
    grouped_places = group_places_by_air_quality(places)
    
    for station_info, place_list in grouped_places.items():
        station_city, station_state = station_info
        print(f"\nüè¢ ‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ‡∏ß‡∏±‡∏î: {station_city}, {station_state}")
        print("-" * 30)
        
        # Display air quality info once per group
        if place_list and place_list[0].get('air_quality'):
            display_air_quality_info(place_list[0]['air_quality'])
            print()
        
        # Display list of places in the group
        for i, place in enumerate(place_list, 1):
            print(f"   {i}. {place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
            if place.get('type'):
                print(f"        ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {place.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
            else:
                print(f"        ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            if place.get('full_address'):
                print(f"      üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: {place.get('full_address', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')[:100]}...")
            else:
                print(f"      üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            if place.get('lat') and place.get('lon'):
                lat, lon = place['lat'], place['lon']
                print(f"        ‡∏û‡∏¥‡∏Å‡∏±‡∏î: {lat:.4f}, {lon:.4f}")
                print(f"      üåê ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà: https://maps.google.com/?q={lat},{lon}")
            else:
                print(f"        ‡∏û‡∏¥‡∏Å‡∏±‡∏î: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
            print()

def display_places(places, title):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    if not places:
        print(f"\n ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {title}")
        return
    
    print(f"\n {title}")
    print("-" * 50)
    
    for i, place in enumerate(places, 1):
        print(f"{i}. {place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
        if place.get('type'):
            print(f"     ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {place.get('type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
        else:
            print(f"     ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        if place.get('full_address'):
            print(f"   üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: {place.get('full_address', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')[:100]}...")
        else:
            print(f"   üè† ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        if place.get('lat') and place.get('lon'):
            lat, lon = place['lat'], place['lon']
            print(f"     ‡∏û‡∏¥‡∏Å‡∏±‡∏î: {lat:.4f}, {lon:.4f}")
            print(f"   üåê ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà: https://maps.google.com/?q={lat},{lon}")
        else:
            print(f"     ‡∏û‡∏¥‡∏Å‡∏±‡∏î: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        print()

def show_api_menu():
    """‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏ô‡∏π‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•"""
    print("\n" + "="*60)
    print(" ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÑ‡∏ó‡∏¢ + ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
    print("="*60)
    print(f" API Usage: {API_CALL_COUNT}/{MAX_API_CALLS} calls used")
    print(f"üóÇÔ∏è  Cache: {len(AIR_QUALITY_CACHE)} ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥")
    print("-"*60)
    print("1.  ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("2.  ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏° (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)") 
    print("3.   ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("4. üéØ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏®)")
    print("5. ‡∏î‡∏π‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®")
    print("6. üìã ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏Å‡∏≤‡∏® - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î API)")
    print("7. üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Cache")
    print("0.  ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    print("-"*60)

def get_combined_tourism(province_name, limit=5):
    """‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏î/‡∏®‡∏≤‡∏™‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô"""
    tourism_types = [
        ("tourism", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß"),
        ("attraction", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à"),
        ("viewpoint", "‡∏à‡∏∏‡∏î‡∏ä‡∏°‡∏ß‡∏¥‡∏ß"),
        ("museum", "‡∏û‡∏¥‡∏û‡∏¥‡∏ò‡∏†‡∏±‡∏ì‡∏ë‡πå"),
        ("zoo", "‡∏™‡∏ß‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå"),
        ("place of worship", "‡∏ß‡∏±‡∏î/‡∏®‡∏≤‡∏™‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô") # Added this type
    ]
    
    print(f"\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô {province_name}")
    print("=" * 50)
    
    all_results = []
    total_found = 0
    
    for place_type, thai_name in tourism_types:
        places = get_nominatim_places(province_name, place_type, limit=limit) # Use passed limit
        found_count = len(places)
        total_found += found_count
        
        # Display search results for each type
        if found_count > 0:
            print(f" {thai_name}: ‡∏û‡∏ö {found_count} ‡πÅ‡∏´‡πà‡∏á")
        else:
            print(f" {thai_name}: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            
        all_results.extend(places)
        
        # Stop once enough places are found (if limit is effective)
        if len(all_results) >= limit:
            break
    
    # Deduplicate and limit the final results
    unique_results = remove_duplicates(all_results)
    final_results = unique_results[:limit]
    
    print(f"\n ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:")
    print(f"   üî¢ ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö‡∏ã‡πâ‡∏≥): {total_found} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print(f"   üîÑ ‡∏´‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏ã‡πâ‡∏≥: {len(unique_results)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print(f"    ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•: {len(final_results)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    print("-" * 50)
    
    return final_results

# --- Cache Management Functions ---
def get_cache_file_path(province_name):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
    today = datetime.date.today().strftime("%Y-%m-%d")
    # Sanitize province_name for filename
    safe_province_name = "".join(c for c in province_name if c.isalnum() or c in (' ', '_')).replace(' ', '_')
    filename = f"{safe_province_name}_{today}.json"
    return os.path.join(CACHE_DIR, filename)

def load_from_cache(province_name):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô)"""
    file_path = get_cache_file_path(province_name)
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f" ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache: {file_path}")
                return data
        except json.JSONDecodeError as e:
            print(f" Cache file ‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ {file_path}: {e}")
            os.remove(file_path) # Remove corrupted file
            return None
        except Exception as e:
            print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î cache ‡∏à‡∏≤‡∏Å {file_path}: {e}")
            return None
    return None

def save_to_cache(province_name, data):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô cache file"""
    os.makedirs(CACHE_DIR, exist_ok=True) # Ensure cache directory exists
    file_path = get_cache_file_path(province_name)
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4) # Use indent for readability
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á cache: {file_path}")
    except Exception as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å cache ‡∏•‡∏á {file_path}: {e}")

def rank_places_by_dust(places, dust_type='aqius'):
    """
    ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® (‡∏ù‡∏∏‡πà‡∏ô) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å)
    Parameters:
    - places: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'air_quality' dict
    - dust_type: ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ù‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö ('aqius', 'pm25', 'pm10')
    """
    if not places:
        return []

    # Map user-friendly dust_type to actual keys in air_quality dict
    if dust_type == 'pm25':
        actual_dust_key = 'pm25'
    elif dust_type == 'pm10':
        actual_dust_key = 'pm10'
    else:  # Default to AQI US
        actual_dust_key = 'aqi'

    places_with_dust_data = []
    places_without_dust_data = []

    for place in places:
        air_quality = place.get('air_quality')
        if air_quality and air_quality.get(actual_dust_key) is not None:
            places_with_dust_data.append(place)
        else:
            places_without_dust_data.append(place)

    # Sort places with dust data by the specified dust_type in ascending order (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å)
    places_with_dust_data.sort(key=lambda x: x['air_quality'][actual_dust_key])

    # Combine sorted places with those without dust data (these will appear at the end)
    return places_with_dust_data + places_without_dust_data

def rank_places_by_category_and_dust(places, dust_type='aqi'):
    """
    ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (attraction, hotel, restaurant) 
    ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1, 2, 3 ‡πÅ‡∏¢‡∏Å‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    Parameters:
    - places: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'air_quality' dict ‡πÅ‡∏•‡∏∞ 'type'
    - dust_type: ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏ù‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö ('aqi', 'pm25', 'pm10')
    """
    if not places:
        return {}

    # Map dust_type to actual keys in air_quality dict
    if dust_type == 'pm25':
        actual_dust_key = 'pm25'
    elif dust_type == 'pm10':
        actual_dust_key = 'pm10'
    else:  # Default to AQI
        actual_dust_key = 'aqi'

    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    categorized_places = {
        'attraction': [],  # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß/‡∏®‡∏≤‡∏™‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô
        'hotel': [],      # ‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°
        'restaurant': []  # ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£
    }

    # ‡πÅ‡∏¢‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    for place in places:
        place_type = place.get('type', '').lower()
        place_copy = place.copy()  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        
        if place_type in ['attraction', 'tourism', 'viewpoint', 'museum', 'zoo', 'place_of_worship']:
            categorized_places['attraction'].append(place_copy)
        elif place_type in ['hotel', 'accommodation', 'hostel', 'resort']:
            categorized_places['hotel'].append(place_copy)
        elif place_type in ['restaurant', 'cafe', 'food', 'bar']:
            categorized_places['restaurant'].append(place_copy)
        else:
            # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠
            place_name = place.get('name', '').lower()
            if any(word in place_name for word in ['‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°', 'hotel', 'resort', 'hostel']):
                categorized_places['hotel'].append(place_copy)
            elif any(word in place_name for word in ['‡∏£‡πâ‡∏≤‡∏ô', 'restaurant', 'cafe', 'food']):
                categorized_places['restaurant'].append(place_copy)
            else:
                categorized_places['attraction'].append(place_copy)

    # ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    ranked_categories = {}
    
    for category, places_list in categorized_places.items():
        if not places_list:
            ranked_categories[category] = []
            continue
            
        # ‡πÅ‡∏¢‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ
        places_with_data = []
        places_without_data = []
        
        for place in places_list:
            air_quality = place.get('air_quality')
            if air_quality and air_quality.get(actual_dust_key) is not None:
                places_with_data.append(place)
            else:
                places_without_data.append(place)
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∏‡πà‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡∏ù‡∏∏‡πà‡∏ô (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å = ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        places_with_data.sort(key=lambda x: x['air_quality'][actual_dust_key])
        
        # ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (‡πÑ‡∏°‡πà‡∏Ç‡πâ‡∏≤‡∏°‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö)
        current_rank = 1
        previous_value = None
        
        for i, place in enumerate(places_with_data):
            current_value = place['air_quality'][actual_dust_key]
            
            # ‡∏´‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡∏•‡∏∞ 1 (‡πÑ‡∏°‡πà‡∏Ç‡πâ‡∏≤‡∏°)
            if previous_value is not None and current_value != previous_value:
                current_rank += 1  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡∏•‡∏∞ 1 ‡πÑ‡∏°‡πà‡∏Ç‡πâ‡∏≤‡∏°‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
            
            place['rank'] = current_rank
            place['category_rank'] = current_rank  # ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ
            
            # ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
            if current_rank == 1:
                place['medal'] = 'ü•á'
                place['rank_text'] = '1'
            elif current_rank == 2:
                place['medal'] = 'ü•à'
                place['rank_text'] = '2'
            elif current_rank == 3:
                place['medal'] = 'ü•â'
                place['rank_text'] = '3'
            else:
                place['medal'] = ''
                place['rank_text'] = str(current_rank)
            
            previous_value = current_value
        
        # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∏‡πà‡∏ô‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
        for place in places_without_data:
            place['rank'] = None
            place['category_rank'] = None
            place['medal'] = ''
            place['rank_text'] = '-'
        
        # ‡∏£‡∏ß‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        ranked_categories[category] = places_with_data + places_without_data

    return ranked_categories
# === Time Series Functions ===
def get_time_series_data(province_name, start_date, end_date, interval='daily'):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ cache ‡πÅ‡∏•‡∏∞ API
    ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Function ‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß
    ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ (backward compatibility)
    """
    import datetime
    from datetime import timedelta
    import json
    import os
    
    try:
        start = datetime.datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.datetime.strptime(end_date, '%Y-%m-%d')
    except ValueError:
        print(" ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö YYYY-MM-DD")
        return []
    
    if start > end:
        print(" ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
        return []
    
    print(f" ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    places = get_combined_tourism(province_name, limit=3)
    
    if not places:
        print(f" ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î {province_name}")
        return []
    
    time_series_data = []
    current_date = start.date()
    end_date_obj = end.date()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå cache ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    cache_dir = os.path.join(os.path.dirname(__file__), 'cache')
    os.makedirs(cache_dir, exist_ok=True)
    
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {len(places)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà")
    
    while current_date <= end_date_obj:
        date_str = current_date.strftime('%Y-%m-%d')
        
        for place in places:
            if not place.get('lat') or not place.get('lon'):
                continue
                
            place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
            
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô cache ‡∏Å‡πà‡∏≠‡∏ô
            cached_data = get_cached_historical_data(place_name, date_str, cache_dir)
            
            if cached_data:
                # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache
                time_series_data.append({
                    'date': date_str,
                    'place_name': place_name,
                    'lat': place['lat'],
                    'lon': place['lon'],
                    'aqi': cached_data.get('aqi', 0),
                    'pm25': cached_data.get('pm25', 0),
                    'pm10': cached_data.get('pm10', 0),
                    'city': cached_data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                    'is_historical': True,
                    'source': 'cache'
                })
                print(f"  üìÅ {date_str}: {place_name} - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache")
            else:
                # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô cache ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á
                if current_date < datetime.date.today():
                    simulated_data = create_realistic_historical_data(
                        place, current_date, province_name
                    )
                    
                    time_series_data.append(simulated_data)
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á cache
                    save_to_time_series_cache(place_name, date_str, simulated_data, cache_dir)
                    print(f"  üîÑ {date_str}: {place_name} - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                elif current_date == datetime.date.today():
                    # ‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å API
                    try:
                        current_air = get_air_quality_by_coordinates(place['lat'], place['lon'])
                        if current_air and current_air.get('pollution'):
                            real_data = {
                                'date': date_str,
                                'place_name': place_name,
                                'lat': place['lat'],
                                'lon': place['lon'],
                                'aqi': current_air['pollution'].get('aqius', 0),
                                'pm25': current_air['pollution'].get('p2', 0),
                                'pm10': current_air['pollution'].get('p1', 0),
                                'city': current_air.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                                'is_historical': False,
                                'source': 'api_realtime'
                            }
                            time_series_data.append(real_data)
                            print(f"  üåê {date_str}: {place_name} - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å API")
                    except Exception as e:
                        print(f"   ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {place_name}: {e}")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≤‡∏° interval
        if interval == 'daily':
            current_date += timedelta(days=1)
        elif interval == 'weekly':
            current_date += timedelta(weeks=1)
        elif interval == 'monthly':
            # ‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            if current_date.month == 12:
                current_date = current_date.replace(year=current_date.year + 1, month=1)
            else:
                current_date = current_date.replace(month=current_date.month + 1)
    
    print(f" ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(time_series_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return time_series_data

def get_cached_historical_data(place_name, date_str, cache_dir):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å cache ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    """
    try:
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        safe_place_name = "".join(c for c in place_name if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        cache_file = os.path.join(cache_dir, f"{safe_place_name}_{date_str}.json")
        
        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f" ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô cache: {e}")
    return None

def save_to_time_series_cache(place_name, date_str, data, cache_dir):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á time series cache
    """
    try:
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤
        safe_place_name = "".join(c for c in place_name if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        cache_file = os.path.join(cache_dir, f"{safe_place_name}_{date_str}.json")
        
        cache_data = {
            'aqi': data.get('aqi', 0),
            'pm25': data.get('pm25', 0),
            'pm10': data.get('pm10', 0),
            'city': data.get('city', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
            'cached_at': datetime.datetime.now().isoformat()
        }
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f" ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å cache: {e}")

def create_realistic_historical_data(place, date, province_name):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pattern ‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•‡πÅ‡∏•‡∏∞‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    """
    import random
    import math
    import datetime
    
    place_name = place.get('name', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    base_aqi = 45
    base_pm25 = 22
    base_pm10 = 35
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    area_type = classify_area_type(place_name, province_name)
    
    if area_type == 'urban':  # ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏´‡∏ç‡πà
        base_aqi += 20
        base_pm25 += 12
        base_pm10 += 15
    elif area_type == 'industrial':  # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
        base_aqi += 35
        base_pm25 += 18
        base_pm10 += 25
    elif area_type == 'rural':  # ‡∏ä‡∏ô‡∏ö‡∏ó
        base_aqi -= 10
        base_pm25 -= 8
        base_pm10 -= 10
    elif area_type == 'coastal':  # ‡∏ä‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏•
        base_aqi -= 5
        base_pm25 -= 5
        base_pm10 -= 8
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•
    month = date.month
    seasonal_multiplier = 1.0
    
    if month in [12, 1, 2]:  # ‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß
        seasonal_multiplier = 1.15
    elif month in [3, 4]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏ï‡πâ‡∏ô - ‡∏´‡∏°‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏±‡∏ô
        seasonal_multiplier = 1.45
    elif month in [5]:  # ‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô‡∏õ‡∏•‡∏≤‡∏¢
        seasonal_multiplier = 1.25
    elif month in [6, 7, 8, 9, 10]:  # ‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_multiplier = 0.65
    elif month in [11]:  # ‡∏´‡∏•‡∏±‡∏á‡∏§‡∏î‡∏π‡∏ù‡∏ô
        seasonal_multiplier = 0.8
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå
    weekday_factor = 1.1 if date.weekday() < 5 else 0.9  # ‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ vs ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
    
    # ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏ö‡∏ö sine wave ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
    day_of_year = date.timetuple().tm_yday
    natural_variation = 1.0 + (0.1 * math.sin(2 * math.pi * day_of_year / 365))
    
    # ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏∏‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô
    daily_random = random.uniform(0.8, 1.2)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    total_factor = seasonal_multiplier * weekday_factor * natural_variation * daily_random
    
    final_aqi = int(base_aqi * total_factor)
    final_pm25 = int(base_pm25 * total_factor)
    final_pm10 = int(base_pm10 * total_factor)
    
    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
    final_aqi = max(15, min(200, final_aqi))
    final_pm25 = max(8, min(120, final_pm25))
    final_pm10 = max(15, min(150, final_pm10))
    
    return {
        'date': date.strftime('%Y-%m-%d'),
        'place_name': place_name,
        'lat': place['lat'],
        'lon': place['lon'],
        'aqi': final_aqi,
        'pm25': final_pm25,
        'pm10': final_pm10,
        'city': place.get('province', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
        'is_historical': True,
        'source': 'generated_realistic'
    }

def classify_area_type(place_name, province_name):
    """
    ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏°‡∏•‡∏û‡∏¥‡∏©
    """
    urban_keywords = ['‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', '‡∏´‡πâ‡∏≤‡∏á', '‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ', '‡∏ï‡∏•‡∏≤‡∏î', '‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•', '‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢']
    industrial_keywords = ['‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô', '‡∏ô‡∏¥‡∏Ñ‡∏°', '‡∏ó‡πà‡∏≤‡πÄ‡∏£‡∏∑‡∏≠', '‡∏™‡∏ô‡∏≤‡∏°‡∏ö‡∏¥‡∏ô']
    coastal_keywords = ['‡∏´‡∏≤‡∏î', '‡∏ó‡∏∞‡πÄ‡∏•', '‡πÄ‡∏Å‡∏≤‡∏∞', '‡∏≠‡πà‡∏≤‡∏ß']
    rural_keywords = ['‡∏ß‡∏±‡∏î', '‡∏õ‡πà‡∏≤', '‡∏†‡∏π‡πÄ‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏ï‡∏Å', '‡∏≠‡∏∏‡∏ó‡∏¢‡∏≤‡∏ô']
    
    place_lower = place_name.lower()
    
    if any(keyword in place_lower for keyword in industrial_keywords):
        return 'industrial'
    elif any(keyword in place_lower for keyword in urban_keywords):
        return 'urban'
    elif any(keyword in place_lower for keyword in coastal_keywords):
        return 'coastal'
    elif any(keyword in place_lower for keyword in rural_keywords):
        return 'rural'
    
    # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    if province_name.lower() in ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ']:
        return 'urban'
    elif province_name.lower() in ['‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ']:
        return 'industrial'
    elif province_name.lower() in ['‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤']:
        return 'coastal'
    else:
        return 'rural'

def analyze_time_series_ranking(time_series_data, sort_by='aqi'):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• time series
    """
    if not time_series_data:
        return {}
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
    place_stats = {}
    
    for data in time_series_data:
        place_name = data['place_name']
        if place_name not in place_stats:
            place_stats[place_name] = {
                'name': place_name,
                'values': [],
                'dates': [],
                'lat': data['lat'],
                'lon': data['lon'],
                'city': data['city']
            }
        
        place_stats[place_name]['values'].append(data[sort_by])
        place_stats[place_name]['dates'].append(data['date'])
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
    ranking_data = []
    for place_name, stats in place_stats.items():
        values = stats['values']
        
        if values:
            avg_value = sum(values) / len(values)
            min_value = min(values)
            max_value = max(values)
            
            ranking_data.append({
                'name': place_name,
                'lat': stats['lat'],
                'lon': stats['lon'],
                'city': stats['city'],
                'average': round(avg_value, 2),
                'minimum': min_value,
                'maximum': max_value,
                'data_points': len(values),
                'values': values,
                'dates': stats['dates']
            })
    
    # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å = ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
    ranking_data.sort(key=lambda x: x['average'])
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö
    for i, place in enumerate(ranking_data, 1):
        place['rank'] = i
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•
        if i == 1:
            place['medal'] = '1'
        elif i == 2:
            place['medal'] = '2'
        elif i == 3:
            place['medal'] = '3'
        else:
            place['medal'] = ''
    
    return {
        'rankings': ranking_data,
        'total_places': len(ranking_data),
        'sort_by': sort_by,
        'best_place': ranking_data[0] if ranking_data else None,
        'worst_place': ranking_data[-1] if ranking_data else None
    }

def display_time_series_ranking(analysis_result):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö time series
    """
    if not analysis_result or not analysis_result.get('rankings'):
        print(" ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö")
        return
    
    rankings = analysis_result['rankings']
    sort_by = analysis_result['sort_by'].upper()
    
    print(f"\n ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® (‡∏ï‡∏≤‡∏° {sort_by})")
    print("=" * 60)
    
    for place in rankings:
        print(f"{place['medal']} {place['rank']}. {place['name']}")
        print(f"    ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {place['average']}")
        print(f"    ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤: {place['minimum']} - {place['maximum']}")
        print(f"   üìÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {place['data_points']} ‡∏à‡∏∏‡∏î")
        print(f"    ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {place['city']}")
        print()
    
    if analysis_result.get('best_place'):
        best = analysis_result['best_place']
        print(f" ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best['name']} (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {best['average']})")
    
    if analysis_result.get('worst_place'):
        worst = analysis_result['worst_place']
        print(f"  ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏¢‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {worst['name']} (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ {sort_by}: {worst['average']})")

def get_forecast_data(province_name, forecast_days=5, interval='daily'):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå forecast_results.json 
    ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ map
    """
    import datetime
    from datetime import timedelta
    import os
    import json
    
    print(f"üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {province_name} ({forecast_days} ‡∏ß‡∏±‡∏ô)")
    
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå forecast_results.json (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ map)
        forecast_file_path = os.path.join(os.path.dirname(__file__), 'forecast_results.json')
        if not os.path.exists(forecast_file_path):
            print(f" ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå forecast_results.json ‡∏ó‡∏µ‡πà {forecast_file_path}")
            return generate_fallback_forecast_data(province_name, forecast_days)
        
        with open(forecast_file_path, 'r', encoding='utf-8') as f:
            forecast_data = json.load(f)
        
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ
        province_forecast = None
        search_names = []
        
        # 1. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤
        search_names.append(province_name)
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        if province_name in DISTRICT_TO_PROVINCE:
            search_names.append(DISTRICT_TO_PROVINCE[province_name])
            print(f" üîÑ ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ '{province_name}' ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î '{DISTRICT_TO_PROVINCE[province_name]}'")
        
        # 3. ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        if province_name in THAI_TO_ENGLISH_PROVINCE:
            search_names.append(THAI_TO_ENGLISH_PROVINCE[province_name])
            print(f" üîÑ ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢ '{province_name}' ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© '{THAI_TO_ENGLISH_PROVINCE[province_name]}'")
        
        # 4. ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ alias mapping
        if province_name in ALIAS_TO_PROVINCE:
            thai_name = ALIAS_TO_PROVINCE[province_name]
            search_names.append(thai_name)
            if thai_name in THAI_TO_ENGLISH_PROVINCE:
                search_names.append(THAI_TO_ENGLISH_PROVINCE[thai_name])
                print(f" üîÑ ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô '{province_name}' ‚Üí '{thai_name}' ‚Üí '{THAI_TO_ENGLISH_PROVINCE[thai_name]}'")
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå forecast
        for search_name in search_names:
            if search_name in forecast_data:
                province_forecast = forecast_data[search_name]
                print(f" ‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{search_name}'")
                break
        
        if not province_forecast:
            print(f" ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {province_name} (‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_names})")
            print(f" üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ó‡∏ô...")
            return generate_fallback_forecast_data(province_name, forecast_days)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ error ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if province_forecast.get('status') == 'error':
            print(f" ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {province_name} ‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ error")
            print(f" üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ó‡∏ô...")
            return generate_fallback_forecast_data(province_name, forecast_days)
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÅ‡∏•‡∏∞ PM10
        pm25_data = province_forecast.get('pm25', [])
        pm10_data = province_forecast.get('pm10', [])
        
        if not pm25_data and not pm10_data:
            print(f" ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÅ‡∏•‡∏∞ PM10 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {province_name}")
            print(f" üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ó‡∏ô...")
            return generate_fallback_forecast_data(province_name, forecast_days)
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà Time Series ‡πÉ‡∏ä‡πâ
        time_series_data = []
        
        # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM2.5 ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∂‡∏á‡πÉ‡∏ä‡πâ PM10
        primary_data = pm25_data if pm25_data else pm10_data
        secondary_data = pm10_data if pm25_data else pm25_data
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ï‡∏≤‡∏° forecast_days
        limited_data = primary_data[:forecast_days] if len(primary_data) >= forecast_days else primary_data
        
        for i, pm_entry in enumerate(limited_data):
            date_str = pm_entry.get('day', '')
            if not date_str:
                continue
            
            # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PM10 ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            pm10_entry = None
            if secondary_data and i < len(secondary_data):
                pm10_entry = secondary_data[i]
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì AQI ‡∏à‡∏≤‡∏Å PM2.5 (‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô US EPA)
            pm25_value = pm_entry.get('avg', 0)
            pm10_value = pm10_entry.get('avg', 0) if pm10_entry else 0
            aqi_value = calculate_aqi_from_pm25(pm25_value)
            
            time_series_data.append({
                'date': date_str,
                'place_name': f"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î{province_name}",  # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÅ‡∏ó‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß
                'lat': 0,  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
                'lon': 0,
                'aqi': aqi_value,
                'pm25': pm25_value,
                'pm10': pm10_value,
                'city': province_name,
                'is_forecast': True,
                'confidence': calculate_forecast_confidence(i),
                'source': 'forecast_api_real_data',
                'min_pm25': pm_entry.get('min', pm25_value),
                'max_pm25': pm_entry.get('max', pm25_value),
                'min_pm10': pm10_entry.get('min', pm10_value) if pm10_entry else pm10_value,
                'max_pm10': pm10_entry.get('max', pm10_value) if pm10_entry else pm10_value
            })
            
            print(f"  üìÖ {date_str}: PM2.5={pm25_value}, PM10={pm10_value}, AQI={aqi_value}")
        
        print(f" ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(time_series_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return time_series_data
        
    except json.JSONDecodeError as e:
        print(f" ‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô JSON: {e}")
        return generate_fallback_forecast_data(province_name, forecast_days)
    except Exception as e:
        print(f" ‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå: {e}")
        return generate_fallback_forecast_data(province_name, forecast_days)
    
def generate_fallback_forecast_data(province_name, forecast_days=7):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
    """
    import datetime
    from datetime import timedelta
    import random
    
    print(f"ÔøΩ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {province_name}")
    
    time_series_data = []
    base_date = datetime.date.today()
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    if province_name in ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', 'Bangkok']:
        base_pm25, base_pm10 = 35, 45
    elif province_name in ['‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', 'Chiang Mai']:
        base_pm25, base_pm10 = 40, 55  # ‡∏´‡∏°‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏±‡∏ô‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠
    elif '‡∏ä‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏•' in province_name or province_name in ['‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', 'Phuket', 'Krabi']:
        base_pm25, base_pm10 = 25, 35  # ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
    else:
        base_pm25, base_pm10 = 30, 40  # ‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥
    
    for i in range(forecast_days):
        forecast_date = base_date + timedelta(days=i)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á
        daily_variation = random.uniform(0.8, 1.2)
        confidence_factor = random.uniform(0.9, 1.1)
        
        pm25_value = int(base_pm25 * daily_variation * confidence_factor)
        pm10_value = int(base_pm10 * daily_variation * confidence_factor)
        aqi_value = calculate_aqi_from_pm25(pm25_value)
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
        pm25_value = max(10, min(100, pm25_value))
        pm10_value = max(15, min(120, pm10_value))
        aqi_value = max(15, min(150, aqi_value))
        
        time_series_data.append({
            'date': forecast_date.strftime('%Y-%m-%d'),
            'place_name': f"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î{province_name}",
            'lat': 0,
            'lon': 0,
            'aqi': aqi_value,
            'pm25': pm25_value,
            'pm10': pm10_value,
            'city': province_name,
            'is_forecast': True,
            'confidence': calculate_forecast_confidence(i),
            'source': 'generated_fallback',
            'min_pm25': int(pm25_value * 0.9),
            'max_pm25': int(pm25_value * 1.1),
            'min_pm10': int(pm10_value * 0.9),
            'max_pm10': int(pm10_value * 1.1)
        })
        
        print(f"  üìÖ {forecast_date.strftime('%Y-%m-%d')}: PM2.5={pm25_value}, PM10={pm10_value}, AQI={aqi_value} (‡∏à‡∏≥‡∏•‡∏≠‡∏á)")
    
    print(f" ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(time_series_data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return time_series_data

def calculate_aqi_from_pm25(pm25):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì AQI ‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ PM2.5 ‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô US EPA
    """
    if pm25 is None or pm25 < 0:
        return 0
    
    # US EPA AQI breakpoints for PM2.5
    if pm25 <= 12.0:
        # Good (0-50)
        return int((50 - 0) / (12.0 - 0.0) * pm25 + 0)
    elif pm25 <= 35.4:
        # Moderate (51-100)
        return int((100 - 51) / (35.4 - 12.1) * (pm25 - 12.1) + 51)
    elif pm25 <= 55.4:
        # Unhealthy for Sensitive Groups (101-150)
        return int((150 - 101) / (55.4 - 35.5) * (pm25 - 35.5) + 101)
    elif pm25 <= 150.4:
        # Unhealthy (151-200)
        return int((200 - 151) / (150.4 - 55.5) * (pm25 - 55.5) + 151)
    elif pm25 <= 250.4:
        # Very Unhealthy (201-300)
        return int((300 - 201) / (250.4 - 150.5) * (pm25 - 150.5) + 201)
    else:
        # Hazardous (301-500)
        return int((500 - 301) / (500.4 - 250.5) * (pm25 - 250.5) + 301)

def calculate_forecast_confidence(day_offset):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (‡∏¢‡∏¥‡πà‡∏á‡πÑ‡∏Å‡∏•‡∏¢‡∏¥‡πà‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô)
    """
    base_confidence = 0.95
    decline_rate = 0.05
    confidence = base_confidence - (day_offset * decline_rate)
    return max(0.6, confidence)  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 60%

# === PM Estimation Functions ===
def estimate_pm25_from_aqi(aqi):
    """Estimate PM2.5 value from AQI (US standard)"""
    if aqi is None or aqi <= 0:
        return None
    
    # AQI to PM2.5 conversion based on US EPA breakpoints
    if aqi <= 50:
        # Good: 0-12 ¬µg/m¬≥
        return int(aqi * 12 / 50)
    elif aqi <= 100:
        # Moderate: 12.1-35.4 ¬µg/m¬≥
        return int(12 + (aqi - 50) * (35.4 - 12) / 50)
    elif aqi <= 150:
        # Unhealthy for Sensitive Groups: 35.5-55.4 ¬µg/m¬≥
        return int(35.4 + (aqi - 100) * (55.4 - 35.4) / 50)
    elif aqi <= 200:
        # Unhealthy: 55.5-150.4 ¬µg/m¬≥
        return int(55.4 + (aqi - 150) * (150.4 - 55.4) / 50)
    elif aqi <= 300:
        # Very Unhealthy: 150.5-250.4 ¬µg/m¬≥
        return int(150.4 + (aqi - 200) * (250.4 - 150.4) / 100)
    else:
        # Hazardous: 250.5+ ¬µg/m¬≥
        return int(250.4 + (aqi - 300) * 100 / 100)

def estimate_pm10_from_aqi(aqi):
    """Estimate PM10 value from AQI (US standard)"""
    if aqi is None or aqi <= 0:
        return None
    
    # AQI to PM10 conversion based on US EPA breakpoints
    if aqi <= 50:
        # Good: 0-54 ¬µg/m¬≥
        return int(aqi * 54 / 50)
    elif aqi <= 100:
        # Moderate: 55-154 ¬µg/m¬≥
        return int(55 + (aqi - 50) * (154 - 55) / 50)
    elif aqi <= 150:
        # Unhealthy for Sensitive Groups: 155-254 ¬µg/m¬≥
        return int(155 + (aqi - 100) * (254 - 155) / 50)
    elif aqi <= 200:
        # Unhealthy: 255-354 ¬µg/m¬≥
        return int(255 + (aqi - 150) * (354 - 255) / 50)
    elif aqi <= 300:
        # Very Unhealthy: 355-424 ¬µg/m¬≥
        return int(355 + (aqi - 200) * (424 - 355) / 100)
    else:
        # Hazardous: 425+ ¬µg/m¬≥
        return int(425 + (aqi - 300) * 75 / 100)

if __name__ == "__main__":
    print("This module is designed to be imported by Flask app, not run directly.")